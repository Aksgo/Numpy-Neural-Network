{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6367a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca0739a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.05\n"
     ]
    }
   ],
   "source": [
    "#numpy dot product\n",
    "inputss = [1,2,3.5]\n",
    "weight = [0.2,0.5,-0.1]\n",
    "bias = 1.2;\n",
    "outputs = np.dot(weight, inputss)+bias;\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34a04b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.76  -0.2    2.464]\n",
      " [ 1.01  -3.148 -0.626]\n",
      " [ 3.39  -0.3    2.332]]\n"
     ]
    }
   ],
   "source": [
    "#4 input neurons with batch size of 3 and 3 output neurons means 3 set of 4 weights and 3 biases for 3 neurons\n",
    "inp = [[1.2, 0.4, -3.2, 1.4],\n",
    "    [0.4, 1.1, 1.3, -0.5],\n",
    "    [0.9, -0.8, -2.3, 1.5]]\n",
    "\n",
    "w1 = [[0.2, 0.8, -0.5, 1.0],\n",
    "    [0.5, -0.26, -0.34, 0.44],\n",
    "    [0.12, -0.3, -0.53, 0.21]]\n",
    "b1 = [1.2, -2.4, 0.45]\n",
    "#now we need to take the transpose of the matrix to multiply them\n",
    "w1 = np.array(w1).T\n",
    "l1_op = np.dot(inp,w1) + b1\n",
    "print(l1_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde35a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.064  4.912  4.032]\n",
      " [ 2.372 -1.522  1.483]\n",
      " [-5.227  4.073  3.632]]\n"
     ]
    }
   ],
   "source": [
    "#adding a second layer to our nn\n",
    "w2=[\n",
    "    [1.11, 1.34, 0.98, -1.04],\n",
    "    [0.32, -0.45, -1.4, -0.23 ],\n",
    "    [1.23, 0.42, 0.33, 1.76]\n",
    "]\n",
    "b2=[-1.34, 0.55, 0.98]\n",
    "w2 = np.array(w2).T\n",
    "l2_op = np.dot(inp,w2) + b2\n",
    "print(l2_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8454a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "def spiral_data(points, classes):\n",
    "    np.random.seed(0)\n",
    "    X = np.zeros((points*classes, 2))\n",
    "    y = np.zeros(points*classes, dtype='uint8')\n",
    "    for class_number in range(classes):\n",
    "        ix = range(points*class_number, points*(class_number+1))\n",
    "        r = np.linspace(0.0, 1, points)  # radius\n",
    "        t = np.linspace(class_number*4, (class_number+1)*4, points) + np.random.randn(points)*0.2\n",
    "        X[ix] = np.c_[r*np.sin(t*2.5), r*np.cos(t*2.5)]\n",
    "        y[ix] = class_number\n",
    "    return X, y\n",
    "X,y = spiral_data(100, 3);\n",
    "print(y)\n",
    "#generate data with 2 inout neurons and specified number of classes as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9368e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dense:\n",
    "    def __init__(self, n_layers, n_neurons):\n",
    "        #n_layers in the no of input neurons and n_neurons is the no of output neurons\n",
    "        np.random.seed(0)\n",
    "        #initializing the weights for one layer with each row in a column have the weights for each input neuron\n",
    "        self.weights=0.10*np.random.randn(n_layers, n_neurons)\n",
    "        #initializing biases columnwise so that they are stacked over each row\n",
    "        #[1,2,3,5]...\n",
    "        self.biases=np.zeros((1,n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        #running the forward pass to calculate w1x1 + w2x2 + ... + b for each output neuron\n",
    "        #inputs is actually a matrix with each row containing one time input of size n_layers\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        #size of output will be thus input set size x n_neurons\n",
    "class Soft_max:\n",
    "    def forward(self, inputs):\n",
    "        #take the maximum along axis=1 (along row) and allocates to a new array\n",
    "        ini = np.max(inputs, axis=1,keepdims=True)\n",
    "        #subtracting values in each row with their row's maximum so that all numbers are in range of -infinity to 0\n",
    "        #and thee^num will be in the range of 0 to 1\n",
    "        inputs = inputs - ini\n",
    "        #calculates the exponentiation of all the values in then input array\n",
    "        exp_layer = np.exp(inputs)\n",
    "        #finding the sum of each row (axis = 1) and thus it creates a single column\n",
    "        mat= np.sum(exp_layer,axis=1)\n",
    "        #reshaping mat to column array\n",
    "        mat = mat.reshape(300,1)\n",
    "        #then it will automatically broacast 300,1 to 300,3\n",
    "        self.output = exp_layer/mat\n",
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        #now the method np.maximum(x1,x2) comapres two arrays (if different shape, then they must be broadcastable)\n",
    "        #and take the maximum value out of the two and alllocates to a new array\n",
    "        self.output = np.maximum(0,inputs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d32ea6fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.         0.00103638 0.00014718 0.0005717  0.00095553]\n",
      " [0.00075135 0.00199405 0.00102515 0.00272585 0.0030446 ]\n",
      " ...\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n",
      "[[0.33333333 0.33333333 0.33333333]\n",
      " [0.33338343 0.33333969 0.33327688]\n",
      " [0.33346423 0.33327849 0.33325728]\n",
      " [0.33358644 0.33305793 0.33335563]\n",
      " [0.33367097 0.3329884  0.33334062]\n",
      " [0.33354979 0.33344213 0.33300809]\n",
      " [0.33381839 0.33293762 0.33324399]\n",
      " [0.33376832 0.33318648 0.33304519]\n",
      " [0.33388376 0.33305874 0.3330575 ]\n",
      " [0.33406798 0.33271366 0.33321836]]\n"
     ]
    }
   ],
   "source": [
    "#applying softmax function to the output\n",
    "layer1 = Layer_Dense(2,5)\n",
    "activation1 = Activation_ReLU()\n",
    "layer1.forward(X)\n",
    "activation1.forward(layer1.output)\n",
    "print(activation1.output)\n",
    "layer2 = Layer_Dense(5,3)\n",
    "layer2.forward(activation1.output)\n",
    "activation2 = Soft_max()\n",
    "activation2.forward(layer2.output)\n",
    "print(activation2.output[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc13fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next aim is to calculate the error and minimize it using backpropagation\n",
    "class Loss:\n",
    "    def calculate(self, output, y):\n",
    "        sample_losses = self.forward(output,y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss\n",
    "class Loss_CategoricalCrossEntropy(Loss):\n",
    "    def forward(self, y_pred, y_target):\n",
    "        samples = len(y_pred)\n",
    "        y_pred = np.clip(y_pred, 1e-7, 1-1e-7)\n",
    "        if len(y_target.shape)==1:\n",
    "            correct_conf = y_pred[range(samples), y_target]\n",
    "        elif len(y_target.shape==2):\n",
    "            correct_conf = np.sum(y_pred*y_target, axis = 1)\n",
    "        y_error = -np.log(correct_conf)\n",
    "        return y_error\n",
    "##to implement kaggle wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "605f7cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0983132858462719\n"
     ]
    }
   ],
   "source": [
    "Lossfunc = Loss_CategoricalCrossEntropy()\n",
    "data_loss = Lossfunc.calculate(activation2.output,y)\n",
    "print(data_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9cca386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16.11809565  0.69314718  0.10536052]\n"
     ]
    }
   ],
   "source": [
    "softmax_output = np.array([\n",
    "    [0.0,0.1,0.2],\n",
    "    [0.1,0.5,0.4],\n",
    "    [0.02,0.9,0.08]  \n",
    "])\n",
    "softmax_output = np.clip(softmax_output, 1e-7 , 1-1e-7)\n",
    "y_target = [0,1,1]\n",
    "#extracting iutput for each \n",
    "print(-np.log(softmax_output[range(len(softmax_output)), y_target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e3804ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function eye in module numpy:\n",
      "\n",
      "eye(N, M=None, k=0, dtype=<class 'float'>, order='C', *, like=None)\n",
      "    Return a 2-D array with ones on the diagonal and zeros elsewhere.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    N : int\n",
      "      Number of rows in the output.\n",
      "    M : int, optional\n",
      "      Number of columns in the output. If None, defaults to `N`.\n",
      "    k : int, optional\n",
      "      Index of the diagonal: 0 (the default) refers to the main diagonal,\n",
      "      a positive value refers to an upper diagonal, and a negative value\n",
      "      to a lower diagonal.\n",
      "    dtype : data-type, optional\n",
      "      Data-type of the returned array.\n",
      "    order : {'C', 'F'}, optional\n",
      "        Whether the output should be stored in row-major (C-style) or\n",
      "        column-major (Fortran-style) order in memory.\n",
      "    \n",
      "        .. versionadded:: 1.14.0\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "    \n",
      "        .. versionadded:: 1.20.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    I : ndarray of shape (N,M)\n",
      "      An array where all elements are equal to zero, except for the `k`-th\n",
      "      diagonal, whose values are equal to one.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    identity : (almost) equivalent function\n",
      "    diag : diagonal 2-D array from a 1-D array specified by the user.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.eye(2, dtype=int)\n",
      "    array([[1, 0],\n",
      "           [0, 1]])\n",
      "    >>> np.eye(3, k=1)\n",
      "    array([[0.,  1.,  0.],\n",
      "           [0.,  0.,  1.],\n",
      "           [0.,  0.,  0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105d761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
